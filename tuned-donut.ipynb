{"cells":[{"cell_type":"markdown","id":"7393e187","metadata":{"papermill":{"duration":0.003446,"end_time":"2023-06-01T06:36:03.764822","exception":false,"start_time":"2023-06-01T06:36:03.761376","status":"completed"},"tags":[],"id":"7393e187"},"source":["# Donut with additional hyperparameter tuning\n","\n","### Notes: This could still absolutely improve with better post text processing. As I have not put a ton of thought into that peice of things yet. I would imagine this is not the final solution for the donut model and there are likely several other creative ways to boost preformance, especially with regaurd to horizontal or vertical bar plots.\n","\n","### A special thank you to @nbroad (Nicholas Broad) for his insights using donut! Go check out his work and discussions"]},{"cell_type":"code","execution_count":1,"id":"c3be35c0","metadata":{"execution":{"iopub.execute_input":"2023-06-01T06:36:03.774605Z","iopub.status.busy":"2023-06-01T06:36:03.773566Z","iopub.status.idle":"2023-06-01T06:36:16.125426Z","shell.execute_reply":"2023-06-01T06:36:16.124475Z"},"papermill":{"duration":12.358206,"end_time":"2023-06-01T06:36:16.127809","exception":false,"start_time":"2023-06-01T06:36:03.769603","status":"completed"},"tags":[],"id":"c3be35c0","outputId":"cf595d32-a7a8-443e-db8e-506fe03a88a7","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1686393934130,"user_tz":-540,"elapsed":454,"user":{"displayName":"전유연","userId":"08454189025897869321"}}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-728832a063ec>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mDonutProcessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mVisionEncoderDecoderConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import re \n","from pathlib import Path\n","from typing import List\n","from functools import partial\n","\n","from transformers import (\n","    DonutProcessor,\n","    VisionEncoderDecoderConfig,\n","    VisionEncoderDecoderModel,\n",")\n","import torch\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from datasets import Image as ds_img\n","from tqdm.notebook import tqdm\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"id":"5f4d5d0a","metadata":{"execution":{"iopub.execute_input":"2023-06-01T06:36:16.135197Z","iopub.status.busy":"2023-06-01T06:36:16.134528Z","iopub.status.idle":"2023-06-01T06:36:16.140545Z","shell.execute_reply":"2023-06-01T06:36:16.139648Z"},"papermill":{"duration":0.011908,"end_time":"2023-06-01T06:36:16.142690","exception":false,"start_time":"2023-06-01T06:36:16.130782","status":"completed"},"tags":[],"id":"5f4d5d0a"},"outputs":[],"source":["class CFG:\n","    \n","    test_grayscale = True\n","    debug_clean = False\n","    \n","    batch_size = 4\n","    image_path = \"/kaggle/input/benetech-making-graphs-accessible/test/images\"\n","    max_length = 512\n","    model_dir = \"/kaggle/input/benetech-donut\"\n","\n","BOS_TOKEN = \"<|BOS|>\"\n","X_START = \"<x_start>\"\n","X_END = \"<x_end>\"\n","Y_START = \"<y_start>\"\n","Y_END = \"<y_end>\"\n","\n","PLACEHOLDER_DATA_SERIES = \"0;0\"\n","PLACEHOLDER_CHART_TYPE = \"line\""]},{"cell_type":"code","execution_count":null,"id":"6abbe8ab","metadata":{"execution":{"iopub.execute_input":"2023-06-01T06:36:16.149583Z","iopub.status.busy":"2023-06-01T06:36:16.149243Z","iopub.status.idle":"2023-06-01T06:36:16.170765Z","shell.execute_reply":"2023-06-01T06:36:16.169788Z"},"papermill":{"duration":0.027339,"end_time":"2023-06-01T06:36:16.172636","exception":false,"start_time":"2023-06-01T06:36:16.145297","status":"completed"},"tags":[],"id":"6abbe8ab"},"outputs":[],"source":["def clean_preds(x: List[str], y: List[str]):\n","    \"\"\"\n","    This function cleans the x and y values predicted by Donut.\n","\n","    Because it is a generative model, it can insert any character in the \n","    model's vocabulary into the prediction string. This function primarily removes\n","    characters that prevent a number from being cast to a float.\n","\n","    Example:\n","\n","    x = [\"11\", \"12\", \"1E\", \"14\", \"15\"]\n","    y = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n","\n","    # float(\"1E\") will throw an error\n","\n","    new_x, new_y = clean_preds(x, y)\n","\n","    new_x = [\"11\", \"12\", \"13\", \"14\", \"15\"]\n","    new_y = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n","\n","    Args:\n","        x (List[str]): The x values predicted by Donut.\n","        y (List[str]): The y values predicted by Donut.\n","\n","    Returns:\n","        x (List[str]): The cleaned x values.\n","        y (List[str]): The cleaned y values.\n","    \"\"\"\n","    \n","    def clean(str_list):\n","        \n","        new_list = []\n","        for temp in str_list:\n","            if \".\" not in temp:\n","                dtype = int\n","            else:\n","                dtype = float\n","            try:\n","                # First try removing whitespace e.g. float(\"10 0\") will fail\n","                temp = dtype(re.sub(\"\\s\", \"\", temp))\n","            except ValueError:\n","\n","                # remove everything that isn't a digit, period, negative sign, or the letter e\n","                # It could be \"1e-5\" or \"-0.134\"\n","\n","                temp = re.sub(r\"[^0-9\\.\\-eE]\", \"\", temp)\n","\n","                if len(temp) == 0:\n","                    temp = 0\n","                else:\n","                    multiple_periods = len(re.findall(r\"\\.\", temp)) > 1\n","                    multiple_negative_signs = len(re.findall(r\"\\-\", temp)) > 1\n","                    multiple_e = len(re.findall(r\"[eE]\", temp)) > 1\n","\n","                    # Put negative sign in from of it all\n","                    if multiple_negative_signs:\n","                        temp = \"-\" + re.sub(r\"\\-\", \"\", temp)\n","\n","                    # Keep first period if there are multiple\n","                    if multiple_periods:\n","                        chunks = temp.split(\".\")\n","                        try:\n","                            temp = chunks[0] + \".\" + \"\".join(chunks[1:])\n","                        except IndexError:\n","                            temp = \"\".join(chunks)\n","                    \n","                    # Keep last e in case it is \"e1e-5\"\n","                    if multiple_e:\n","                        while temp.lower().startswith(\"e\"):\n","                            temp = temp[1:]\n","                        \n","                        while temp.lower().endswith(\"e\"):\n","                            temp = temp[:-1]\n","                            \n","                        chunks = temp.split(\"e\")\n","                        try:\n","                            temp = chunks[0:-1] + \"e\" + \"\".join(chunks[-1])\n","                        except IndexError:\n","                            temp = \"\".join(chunks)\n","                try:\n","                    temp = dtype(temp)\n","                except ValueError:\n","                    temp = 0\n","                    \n","            new_list.append(temp)\n","\n","        return new_list\n","\n","    all_x_chars = \"\".join(x)\n","    all_y_chars = \"\".join(y)\n","\n","    frac_num_x = len(re.sub(r\"[^\\d]\", \"\", all_x_chars)) / len(all_x_chars)\n","    frac_num_y = len(re.sub(r\"[^\\d]\", \"\", all_y_chars)) / len(all_y_chars)\n","    \n","    print(frac_num_x, frac_num_y)\n","\n","    if CFG.debug_clean:\n","        print(f\"x before clean (len={len(x)})\", x)\n","        print(f\"y before clean (len={len(y)})\", y)\n","\n","    if frac_num_x >= 0.5:\n","        x = clean(x)\n","    else:\n","        x = [s.strip() for s in x]\n","    \n","    \n","    if frac_num_y >= 0.5:\n","        y = clean(y)\n","    else:\n","        y = [s.strip() for s in y]\n","        \n","    if CFG.debug_clean:\n","        print(f\"x after clean (len={len(x)})\", x)\n","        print(f\"y after clean (len={len(x)})\", x)\n","\n","    return x, y\n","    \n","\n","def string2preds(pred_string: str):\n","    \"\"\"\n","    Convert the prediction string from Donut to a chart type and x and y values.\n","\n","    Checks to make sure the special tokens are present and that the x and y values are not empty.\n","    Will truncate the list of values to the smaller length of the two lists. This is because the \n","    lengths of the x and y values must be the same to earn any points.\n","\n","    Args:\n","        pred_string (str): The prediction string from Donut.\n","\n","    Returns:\n","        chart_type (str): The chart type predicted by Donut.\n","        x (List[str]): The x values predicted by Donut.\n","        y (List[str]): The y values predicted by Donut.\n","    \"\"\"\n","\n","    if \"<dot>\" in pred_string:\n","        chart_type = \"dot\"\n","    elif \"<horizontal_bar>\" in pred_string:\n","        chart_type = \"horizontal_bar\"\n","    elif \"<vertical_bar>\" in pred_string:\n","        chart_type = \"vertical_bar\"\n","    elif \"<scatter>\" in pred_string:\n","        chart_type = \"scatter\"\n","    elif \"<line>\" in pred_string:\n","        chart_type = \"line\"\n","    else:\n","        return \"vertical_bar\", [], []\n","    \n","    \n","    if not all([x in pred_string for x in [X_START, X_END, Y_START, Y_END]]):\n","        return chart_type, [], []\n","    \n","    pred_string = re.sub(r\"<one>\", \"1\", pred_string)\n","\n","    x = pred_string.split(X_START)[1].split(X_END)[0].split(\";\")\n","    y = pred_string.split(Y_START)[1].split(Y_END)[0].split(\";\")\n","\n","    if len(x) == 0 or len(y) == 0:\n","        return chart_type, [], []\n","\n","    x, y = clean_preds(x, y)\n","\n","    return chart_type, x, y"]},{"cell_type":"code","execution_count":null,"id":"e6faecc5","metadata":{"execution":{"iopub.execute_input":"2023-06-01T06:36:16.179833Z","iopub.status.busy":"2023-06-01T06:36:16.179330Z","iopub.status.idle":"2023-06-01T06:36:48.315564Z","shell.execute_reply":"2023-06-01T06:36:48.314589Z"},"papermill":{"duration":32.144769,"end_time":"2023-06-01T06:36:48.320032","exception":false,"start_time":"2023-06-01T06:36:16.175263","status":"completed"},"tags":[],"id":"e6faecc5","outputId":"711f5b14-0c5d-4b3b-c44a-0c7b2a9294b4","colab":{"referenced_widgets":["0d2f500a2f63413e8c22f4d43a6f2b88"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d2f500a2f63413e8c22f4d43a6f2b88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0.8888888888888888 0.47619047619047616\n","0.13333333333333333 0.5\n","0.6363636363636364 0.6363636363636364\n"]}],"source":["image_dir = Path(CFG.image_path)\n","images = list(image_dir.glob(\"*.jpg\"))\n","\n","ds = Dataset.from_dict(\n","    {\"image_path\": [str(x) for x in images], \"id\": [x.stem for x in images]}\n",").cast_column(\"image_path\", ds_img())\n","\n","def preprocess(examples, processor):\n","    pixel_values = []\n","\n","    for sample in examples[\"image_path\"]:\n","        arr = np.array(sample)\n","        \n","        # There are some grayscale images that were making this fail\n","        # This prevents that.\n","        if len(arr.shape) == 2:\n","            print(\"Changing grayscale to 3 channel format\")\n","            print(arr.shape)\n","            arr = np.stack([arr]*3, axis=-1)\n","        \n","        pixel_values.append(processor(arr, random_padding=True).pixel_values)\n","        \n","        \n","    return {\n","        \"pixel_values\": torch.tensor(np.vstack(pixel_values)),\n","    }\n","\n","model = VisionEncoderDecoderModel.from_pretrained(CFG.model_dir)\n","model.eval()\n","\n","device = torch.device(\"cuda:0\")\n","\n","model.to(device)\n","decoder_start_token_id = model.config.decoder_start_token_id\n","processor = DonutProcessor.from_pretrained(CFG.model_dir)\n","\n","ids = ds[\"id\"]\n","ds.set_transform(partial(preprocess, processor=processor))\n","\n","data_loader = DataLoader(\n","    ds, batch_size=CFG.batch_size, shuffle=False\n",")\n","\n","\n","all_generations = []\n","for batch in tqdm(data_loader):\n","    pixel_values = batch[\"pixel_values\"].to(device)\n","\n","    batch_size = pixel_values.shape[0]\n","\n","    decoder_input_ids = torch.full(\n","        (batch_size, 1),\n","        decoder_start_token_id,\n","        device=pixel_values.device,\n","    )\n","\n","    try:\n","        outputs = model.generate(\n","            pixel_values,\n","            decoder_input_ids=decoder_input_ids,\n","            max_length=CFG.max_length,\n","            early_stopping=True,\n","            pad_token_id=processor.tokenizer.pad_token_id,\n","            eos_token_id=processor.tokenizer.eos_token_id,\n","            use_cache=True,\n","            num_beams=2,       #1 int    (1 - 10)\n","            temperature=.9,     #1 float  (0 -  ) less div - more div\n","            top_k=1,           #1 int    (1 -  ) less div - more div\n","            top_p=.4,           #1 float (0 - 1) more div - less div\n","            return_dict_in_generate=True,\n","        )\n","\n","        all_generations.extend(processor.batch_decode(outputs.sequences))\n","        \n","    except:\n","        all_generations.extend([\"\"]*batch_size)\n","        \n","chart_types, x_preds, y_preds = [], [], []\n","for gen in all_generations:\n","\n","    try:\n","        chart_type, x, y = string2preds(gen)\n","        new_chart_type = chart_type\n","        x_str = \";\".join(list(map(str, x)))\n","        y_str = \";\".join(list(map(str, y)))\n","\n","    except Exception as e:\n","        print(\"Failed to convert to string:\", gen)\n","        print(e)\n","        new_chart_type = PLACEHOLDER_CHART_TYPE\n","        x_str = PLACEHOLDER_DATA_SERIES\n","        y_str = PLACEHOLDER_DATA_SERIES\n","            \n","    if len(x_str) == 0:\n","        x_str = PLACEHOLDER_DATA_SERIES\n","    if len(y_str) == 0:\n","        y_str = PLACEHOLDER_DATA_SERIES\n","    \n","    chart_types.append(new_chart_type)\n","    x_preds.append(x_str)\n","    y_preds.append(y_str)\n","        \n","\n","sub_df = pd.DataFrame(\n","    data={\n","        \"id\": [f\"{id_}_x\" for id_ in ids] + [f\"{id_}_y\" for id_ in ids],\n","        \"data_series\": x_preds + y_preds,\n","        \"chart_type\": chart_types * 2,\n","    }\n",")\n","\n","sub_df.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"id":"46cc71bb","metadata":{"execution":{"iopub.execute_input":"2023-06-01T06:36:48.327214Z","iopub.status.busy":"2023-06-01T06:36:48.326929Z","iopub.status.idle":"2023-06-01T06:36:48.342207Z","shell.execute_reply":"2023-06-01T06:36:48.341183Z"},"papermill":{"duration":0.021455,"end_time":"2023-06-01T06:36:48.344568","exception":false,"start_time":"2023-06-01T06:36:48.323113","status":"completed"},"tags":[],"id":"46cc71bb","outputId":"bc4edf5d-307e-4404-def2-20307b4023e0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>data_series</th>\n","      <th>chart_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000b92c3b098_x</td>\n","      <td>0;6;12;18;24</td>\n","      <td>line</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01b45b831589_x</td>\n","      <td>0;0</td>\n","      <td>vertical_bar</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00f5404753cf_x</td>\n","      <td>0;0</td>\n","      <td>scatter</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00dcf883a459_x</td>\n","      <td>Group 1;Group 2</td>\n","      <td>vertical_bar</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>007a18eb4e09_x</td>\n","      <td>0.0;0.4;0.8;1.2;1.6;2.0;2.4</td>\n","      <td>line</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>000b92c3b098_y</td>\n","      <td>-0.0;-1.4;-2.1;-2.1;-3.3</td>\n","      <td>line</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>01b45b831589_y</td>\n","      <td>0;0</td>\n","      <td>vertical_bar</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>00f5404753cf_y</td>\n","      <td>0;0</td>\n","      <td>scatter</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>00dcf883a459_y</td>\n","      <td>3.7</td>\n","      <td>vertical_bar</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>007a18eb4e09_y</td>\n","      <td>0.0;0.0;0.0;0.0;0.0;0.0;0.0</td>\n","      <td>line</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               id                  data_series    chart_type\n","0  000b92c3b098_x                 0;6;12;18;24          line\n","1  01b45b831589_x                          0;0  vertical_bar\n","2  00f5404753cf_x                          0;0       scatter\n","3  00dcf883a459_x              Group 1;Group 2  vertical_bar\n","4  007a18eb4e09_x  0.0;0.4;0.8;1.2;1.6;2.0;2.4          line\n","5  000b92c3b098_y     -0.0;-1.4;-2.1;-2.1;-3.3          line\n","6  01b45b831589_y                          0;0  vertical_bar\n","7  00f5404753cf_y                          0;0       scatter\n","8  00dcf883a459_y                          3.7  vertical_bar\n","9  007a18eb4e09_y  0.0;0.0;0.0;0.0;0.0;0.0;0.0          line"]},"metadata":{},"output_type":"display_data"}],"source":["display(sub_df)"]},{"cell_type":"code","source":[],"metadata":{"id":"Ix5cbSCM6HLj"},"id":"Ix5cbSCM6HLj","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":58.81535,"end_time":"2023-06-01T06:36:51.684860","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-01T06:35:52.869510","version":"2.4.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}